/**
 * LeRobot Documentation Generator
 *
 * Generates README.md with HuggingFace dataset card YAML front matter.
 */

import type { LeRobotCameraView } from './metadata';

/**
 * Generate HuggingFace Dataset Card (README.md) with YAML front matter
 */
export function generateReadme(
  datasetName: string,
  robotId: string,
  episodeCount: number,
  hasVideo: boolean,
  cameraViews?: LeRobotCameraView[]
): string {
  const approxFrames = episodeCount * 90;
  const views = cameraViews ?? (hasVideo ? ['cam_high' as LeRobotCameraView] : []);

  const yamlFrontMatter = `---
# Dataset Card for ${datasetName}
license: apache-2.0
task_categories:
  - robotics
tags:
  - lerobot
  - sim-to-real
  - imitation-learning
  - robot-manipulation
  - ${robotId}
  - robosim${views.length > 1 ? '\n  - multi-camera' : ''}
pretty_name: ${datasetName}
size_categories:
  - ${episodeCount < 100 ? 'n<1K' : episodeCount < 1000 ? '1K<n<10K' : '10K<n<100K'}
configs:
  - config_name: default
    data_files:
      - split: train
        path: data/chunk-000/*.parquet
dataset_info:
  features:
    - name: observation.state
      dtype: float32
      shape: [6]
    - name: observation.velocity
      dtype: float32
      shape: [6]
    - name: action
      dtype: float32
      shape: [6]
    - name: timestamp
      dtype: float32
    - name: episode_index
      dtype: int64
    - name: frame_index
      dtype: int64
  splits:
    - name: train
      num_examples: ${approxFrames}
---

# ${datasetName}`;

  return `${yamlFrontMatter}

A robotics dataset recorded with RoboSim, compatible with HuggingFace LeRobot.

## Quick Start

### 1. Convert to Parquet (Required)

The episode files are in JSON format for browser compatibility. Convert to true Parquet:

\`\`\`bash
pip install pandas pyarrow
python convert_to_parquet.py
\`\`\`

### 2. Use with LeRobot

\`\`\`python
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset

# Load from local directory
dataset = LeRobotDataset("path/to/${datasetName}")

# Or upload to HuggingFace Hub first
# huggingface-cli upload your-username/${datasetName} .
# dataset = LeRobotDataset("your-username/${datasetName}")
\`\`\`

## Dataset Info

| Property | Value |
|----------|-------|
| Robot | ${robotId} |
| Episodes | ${episodeCount} |
| Format | LeRobot v3.0 |
| Video | ${hasVideo ? 'Yes' : 'No'} |

## Structure

\`\`\`
${datasetName}/
├── meta/
│   ├── info.json          # Dataset configuration
│   ├── stats.json         # Feature statistics
│   ├── episodes.jsonl     # Episode metadata
│   └── tasks.jsonl        # Task definitions
├── data/
│   └── chunk-000/
│       └── episode_*.parquet  # Episode data
${views.length > 0 ? `├── videos/\n${views.map(v => `│   └── observation.images.${v}/\n│       └── episode_*.mp4`).join('\n')}\n` : ''}├── convert_to_parquet.py  # Conversion script
└── README.md
\`\`\`

## Training

### With LeRobot

\`\`\`bash
# Train ACT policy (recommended for manipulation)
python lerobot/scripts/train.py \\
    dataset_repo_id=path/to/${datasetName} \\
    policy=act_${robotId.replace('-', '_')} \\
    training.num_epochs=2000

# Or Diffusion Policy for more complex tasks
python lerobot/scripts/train.py \\
    dataset_repo_id=path/to/${datasetName} \\
    policy=diffusion_${robotId.replace('-', '_')} \\
    training.num_epochs=2000
\`\`\`

### With Google Colab (Free GPU)

1. Open the [RoboSim Training Notebook](https://colab.research.google.com/github/hshadab/robosim/blob/main/notebooks/train_so101_colab.ipynb)
2. Upload this dataset or enter your HuggingFace dataset ID
3. Run all cells (~2 hours on free T4 GPU)

## Sim-to-Real Transfer

This dataset includes domain randomization for better real-world transfer:

- **Visual randomization**: Varied lighting, textures, camera angles
- **Image augmentation**: Gaussian noise, motion blur, brightness/contrast variation
- **Motion variation**: Slight randomization in trajectory timing and targets

### Deployment Tips

1. **Camera calibration**: Match the simulation camera FOV and position
2. **Action scaling**: Joint angles are in radians (LeRobot standard)
3. **Gripper mapping**: Gripper values are normalized 0-1 (0=closed, 1=open)

## Citation

If you use this dataset, please cite RoboSim:

\`\`\`bibtex
@software{robosim2024,
  title = {RoboSim: Browser-Based Robot Simulation for Imitation Learning},
  author = {RoboSim Contributors},
  year = {2024},
  url = {https://github.com/hshadab/robosim}
}
\`\`\`

---
*Generated by [RoboSim](https://robosim.dev) • LeRobot v3.0 Compatible*
`;
}
